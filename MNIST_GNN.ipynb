{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1984931b",
   "metadata": {},
   "source": [
    "# Libraries Model GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d052835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f7f9c",
   "metadata": {},
   "source": [
    "# Loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "723355d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# transformations\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# download and loading training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# download and loading test dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b850e",
   "metadata": {},
   "source": [
    "# Constructing Model GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8c1452a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        # converting 28x28x1 --> 26x26x32\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "        self.d1 = nn.Linear(26 * 26 * 32, 128)\n",
    "        self.d2 = nn.Linear(128,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # converting 32 x 1 x 28 x 28 --> 32 x 32 x 26 x 26\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # flatten --> 32 x (32 * 26 * 26)\n",
    "        \n",
    "        x = x.flatten(start_dim = 1)\n",
    "        \n",
    "        # 32 x (32 * 26 * 26) --> 32 x 128\n",
    "        x = self.d1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # logits --> 32 x 10\n",
    "        logits = self.d2(x)\n",
    "        out = F.softmax(logits, dim = 1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cad164",
   "metadata": {},
   "source": [
    "# Training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8be7619f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MyModel()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d4f6f78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 1.6540 | Train Accuracy: 0.81\n",
      "Epoch: 1 | Loss: 1.4907 | Train Accuracy: 0.97\n",
      "Epoch: 2 | Loss: 1.4801 | Train Accuracy: 0.98\n",
      "Epoch: 3 | Loss: 1.4758 | Train Accuracy: 0.99\n",
      "Epoch: 4 | Loss: 1.4730 | Train Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    \n",
    "    ## training step\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # forward + backpropagation + loss\n",
    "        \n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # update model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += (torch.argmax(logits, 1).flatten() == labels).type(torch.float).mean().item()\n",
    "        \n",
    "    print(\"Epoch: %d | Loss: %.4f | Train Accuracy: %.2f\" \\\n",
    "         %(epoch, train_running_loss / i, train_acc/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b64e437a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "test_acc = 0.0\n",
    "for i, (images, labels) in enumerate(testloader, 0):\n",
    "    images = images.to(device)\n",
    "    labaels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    test_acc += (torch.argmax(outputs, 1).flatten() == labels).type(torch.float).mean().item()\n",
    "    preds = torch.argmax(outputs, 1).flatten().cpu().numpy()\n",
    "    \n",
    "print(\"Test Accuracy: %.2f\"%(test_acc/i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d748b306-8aaf-47dc-9fd0-8dbdd3b024fb",
   "metadata": {},
   "source": [
    "# Libraries Graphing GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb7e4d9c-5188-41d0-9583-72c29f2cd471",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import sklearn.manifold\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eedfff1-9ba6-4808-9b86-1c421d6ad413",
   "metadata": {},
   "source": [
    "# Defining model for GNN Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec1f8205-45cb-45a5-8ec8-be1243614683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNNStack(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, task='node'):\n",
    "        super(GNNStack, self).__init__()\n",
    "        self.task = task\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(self.build_conv_model(input_dim, hidden_dim))\n",
    "        self.lns = nn.ModuleList()\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        for l in range(2):\n",
    "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "        if not (self.task == 'node' or self.task == 'graph'):\n",
    "            raise RuntimeError('Unknown task.')\n",
    "\n",
    "        self.dropout = 0.25\n",
    "        self.num_layers = 3\n",
    "\n",
    "    def build_conv_model(self, input_dim, hidden_dim):\n",
    "        # refer to pytorch geometric nn module for different implementation of GNNs.\n",
    "        if self.task == 'node':\n",
    "            return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
    "        else:\n",
    "            return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "                                  nn.ReLU(), nn.Linear(hidden_dim, hidden_dim)))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        if data.num_node_features == 0:\n",
    "          x = torch.ones(data.num_nodes, 1)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            if not i == self.num_layers - 1:\n",
    "                x = self.lns[i](x)\n",
    "\n",
    "        if self.task == 'graph':\n",
    "            x = pyg_nn.global_mean_pool(x, batch)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        return emb, F.log_softmax(x, dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a081b-cc79-43fe-87dd-db94e7bb33c6",
   "metadata": {},
   "source": [
    "## Training setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41b97271-0dd5-432c-9bb9-febc065e45ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(dataset, task, writer):\n",
    "    if task == 'graph':\n",
    "        data_size = len(dataset)\n",
    "        loader = DataLoader(dataset[:int(data_size * 0.8)], batch_size=64, shuffle=True)\n",
    "        test_loader = DataLoader(dataset[int(data_size * 0.8):], batch_size=64, shuffle=True)\n",
    "    else:\n",
    "        test_loader = loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # build model\n",
    "    model = GNNStack(max(dataset.num_node_features, 1), 32, dataset.num_classes, task=task)\n",
    "    opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # train\n",
    "    for epoch in range(200):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for batch in loader:\n",
    "            #print(batch.train_mask, '----')\n",
    "            opt.zero_grad()\n",
    "            embedding, pred = model(batch)\n",
    "            label = batch.y\n",
    "            if task == 'node':\n",
    "                pred = pred[batch.train_mask]\n",
    "                label = label[batch.train_mask]\n",
    "            loss = model.loss(pred, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "        total_loss /= len(loader.dataset)\n",
    "        writer.add_scalar(\"loss\", total_loss, epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_acc = test(test_loader, model)\n",
    "            print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(\n",
    "                epoch, total_loss, test_acc))\n",
    "            writer.add_scalar(\"test accuracy\", test_acc, epoch)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84023a1-24ce-4831-a0b8-c20a0f9774d6",
   "metadata": {},
   "source": [
    "# Test setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c1d186d-297e-4a28-9f6b-80b4792608a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(loader, model, is_validation=False):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            emb, pred = model(data)\n",
    "            pred = pred.argmax(dim=1)\n",
    "            label = data.y\n",
    "\n",
    "        if model.task == 'node':\n",
    "            mask = data.val_mask if is_validation else data.test_mask\n",
    "            # node classification: only evaluate on nodes in test set\n",
    "            pred = pred[mask]\n",
    "            label = data.y[mask]\n",
    "            \n",
    "        correct += pred.eq(label).sum().item()\n",
    "    \n",
    "    if model.task == 'graph':\n",
    "        total = len(loader.dataset) \n",
    "    else:\n",
    "        total = 0\n",
    "        for data in loader.dataset:\n",
    "            total += torch.sum(data.test_mask).item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282dea13-9f9e-426b-a998-693cfc4270f1",
   "metadata": {},
   "source": [
    "## Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a1d0601-2afc-482b-8251-81df2e60c93f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tensorboard http://localhost:6006/\n",
    "%reload_ext tensorboard\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c719c3a8-5de5-4b7a-a477-6b026c60c049",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 1.8290. Test accuracy: 0.1667\n",
      "Epoch 10. Loss: 1.7348. Test accuracy: 0.2167\n",
      "Epoch 20. Loss: 1.7236. Test accuracy: 0.2500\n",
      "Epoch 30. Loss: 1.6919. Test accuracy: 0.2083\n",
      "Epoch 40. Loss: 1.6730. Test accuracy: 0.2667\n",
      "Epoch 50. Loss: 1.6934. Test accuracy: 0.2583\n",
      "Epoch 60. Loss: 1.6716. Test accuracy: 0.2667\n",
      "Epoch 70. Loss: 1.6721. Test accuracy: 0.2667\n",
      "Epoch 80. Loss: 1.6234. Test accuracy: 0.3083\n",
      "Epoch 90. Loss: 1.6522. Test accuracy: 0.2583\n",
      "Epoch 100. Loss: 1.6506. Test accuracy: 0.2750\n",
      "Epoch 110. Loss: 1.5910. Test accuracy: 0.3083\n",
      "Epoch 120. Loss: 1.6359. Test accuracy: 0.2667\n",
      "Epoch 130. Loss: 1.5770. Test accuracy: 0.2333\n",
      "Epoch 140. Loss: 1.6646. Test accuracy: 0.2167\n",
      "Epoch 150. Loss: 1.5855. Test accuracy: 0.3083\n",
      "Epoch 160. Loss: 1.5285. Test accuracy: 0.3083\n",
      "Epoch 170. Loss: 1.6050. Test accuracy: 0.2667\n",
      "Epoch 180. Loss: 1.5086. Test accuracy: 0.3250\n",
      "Epoch 190. Loss: 1.5082. Test accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "dataset = TUDataset(root='/tmp/ENZYMES', name='ENZYMES')\n",
    "dataset = dataset.shuffle()\n",
    "task = 'graph'\n",
    "\n",
    "model = train(dataset, task, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d102a36f-409d-456f-a000-739646fde042",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-34226e1ce17c71ee\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-34226e1ce17c71ee\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir \"./log\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
